<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Channel TTS Demo — Audio Comparisons</title>
  <meta name="color-scheme" content="light dark">
  <link rel="stylesheet" href="static/css/style.css">
  <!-- Open Graph / Twitter -->
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://tts.ch.dev/">
  <meta property="og:title" content="Introducing Channel TTS">
  <meta property="og:description" content="전화 상담을 위한 최신 TTS 모델을 소개합니다. 자연스럽고 친근한 음성으로 고객과의 소통을 돕습니다.">
  <meta property="og:image" content="https://tts.ch.dev/static/img/og-chtts.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Introducing Channel TTS">
  <meta name="twitter:description" content="전화 상담을 위한 최신 TTS 모델을 소개합니다. 자연스럽고 친근한 음성으로 고객과의 소통을 돕습니다.">
  <meta name="twitter:image" content="https://tts.ch.dev/static/img/og-chtts.png">
  <!-- MathJax config (반드시 loader 스크립트보다 먼저!) -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['\\(', '\\)'], ['$', '$']],
        displayMath: [['\\[', '\\]'], ['$$', '$$']]
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    };
  </script>
  <!-- 가장 가벼운 CHTML 빌드 -->
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

</head>
<body>
  <div class="container">
    <!-- Header -->
    <header class="nav">
      <div class="brand">
        <picture class="brand-logo">
          <!-- 다크 모드에서는 흰 로고 사용 -->
          <source srcset="static/img/ch-logo-white-ko.png" media="(prefers-color-scheme: dark)">
          <!-- 라이트 모드에서는 보라+검정 로고 -->
          <img src="static/img/ch-logo-ko.png" alt="채널톡 로고" class="brand-logo-img" />
        </picture>
      </div>
      <div class="nav-actions">
        <a class="btn" href="https://channel.io/ko/careers/9ae3038a-70e9-40da-85dd-c7c854bb4527" target="_blank" rel="noopener">함께하고 싶다면</a>
        <a class="btn" href="https://channel.io" target="_blank" rel="noopener">더 알아보기 →</a>
      </div>
    </header>
    

    <!-- Hero (논문 타이틀 스타일) -->
    <section class="hero">
      <h1 class="title">Channel TTS: Towards Real-World Prosody for Conversational Agents</h1>
    
      <p class="authors">
        <a href="https://seungyounshin.github.io" target="_blank">Seungyoun Shin</a><sup>1</sup>, 
        <a href="https://skswldndi.github.io" target="_blank">Jiwoo Kim</a><sup>1</sup>, 
        Dongha Ahn<sup>1</sup>, 
        Sungwook Jeon<sup>1</sup>
      </p>
      <p class="affiliation"><sup>1</sup>Channel Corp.</p>
    
      <div class="links">
        <a class="link-btn" href="#">🎧 Demo</a>
        <a class="link-btn" href="https://arxiv.org/abs/2509.18531" target="_blank" rel="noopener">📄 Paper</a>
        <a class="link-btn" href="#">💻 Code</a>
      </div>
    </section>

    <!-- Live Demo -->
    <section id="live-demo" class="live-demo">
      <h2>🎤 Live Demo</h2>
      <div class="demo-container">
        <div class="demo-card">
          <div class="demo-textarea-wrapper">
            <textarea 
              id="demo-text" 
              rows="4" 
              placeholder="여러 상용 TTS가 이미 존재하지만, 저희가 자체 모델을 만드는 이유는 명확합니다."
            >여러 상용 TTS가 이미 존재하지만, 저희가 자체 모델을 만드는 이유는 명확합니다.</textarea>
            <button id="demo-clear-btn" class="demo-clear-btn" title="텍스트 지우기">
              <svg width="16" height="16" viewBox="0 0 16 16" fill="none">
                <path d="M12 4L4 12M4 4L12 12" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
              </svg>
            </button>
          </div>
          
          <div class="demo-controls">
            <button id="demo-play-btn" class="demo-btn-play">
              <svg class="icon-play" width="20" height="20" viewBox="0 0 20 20" fill="none">
                <path d="M5 3L15 10L5 17V3Z" fill="currentColor"/>
              </svg>
              <span>재생하기</span>
            </button>
            <button id="demo-stop-btn" class="demo-btn-stop" disabled>
              <svg width="16" height="16" viewBox="0 0 16 16" fill="none">
                <rect x="3" y="3" width="10" height="10" fill="currentColor"/>
              </svg>
            </button>
          </div>

          <div id="demo-status" class="demo-status"></div>
        </div>
        
        <div class="demo-footer">
          <p>💡 실시간 스트리밍 TTS API를 사용합니다. 텍스트를 입력하고 재생 버튼을 누르면 즉시 음성이 재생됩니다.</p>
        </div>
      </div>
    </section>

    <!-- 듣기 비교 -->
    <section id="listen" class="listen">
      <h2>오디오 비교</h2>
      <div class="divider"></div>
      <!--<p class="note"></p>*전화는 8Khz이기 때문에 모두 <strong>8Khz로 변환</strong>하였습니다.</p>-->

      <!-- Row 1 -->
      <div class="utterance-block">
        안녕하세요 채널톡 AI 에이전트 알프입니다.
        <div class="audios">
          <div class="col">
            <div class="label">GPT-4o-mini-tts (sage)</div>
            <audio controls preload="metadata">
              <source src="static/audios/openai_1.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
            <audio controls preload="metadata">
              <source src="static/audios/elevenlabs_1.mp3" type="audio/mpeg" />
            </audio>
          </div>
          <div class="col">
            <div class="label">국내 TTS</div>
            <audio controls preload="metadata">
              <source src="static/audios/supertone_1.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">Ours</div>
            <audio controls preload="metadata">
              <source src="static/audios/ours1.wav" type="audio/wav" />
            </audio>
          </div>
        </div>
      </div>

      <!-- Row 2 -->
      <div class="utterance-block">
        서류상 이상이 있다면 알려주시면 감사하겠습니다.
        <div class="audios">
          <div class="col">
            <div class="label">GPT-4o-mini-tts (sage)</div>
            <audio controls preload="metadata">
              <source src="static/audios/openai_2.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
            <audio controls preload="metadata">
              <source src="static/audios/elevenlabs_2.mp3" type="audio/mpeg" />
            </audio>
          </div>
          <div class="col">
            <div class="label">국내 TTS</div>
            <audio controls preload="metadata">
              <source src="static/audios/supertone_2.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">Ours</div>
            <audio controls preload="metadata">
              <source src="static/audios/ours2.wav" type="audio/wav" />
            </audio>
          </div>
        </div>
      </div>

      <!-- Row 3 -->
      <div class="utterance-block">
        FAQ나 도큐먼트에서 '홈페이지 주소를 입력하거나 이미지를 등록하면 텍스트, 이미지 등을 크롤링하여 답변하는 기능'에 대한 정보가 없어 조금 더 자세한 설명을 부탁드려도 될까요?
        <div class="audios">
          <div class="col">
            <div class="label">GPT-4o-mini-tts (sage)</div>
            <audio controls preload="metadata">
              <source src="static/audios/openai_3.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
            <audio controls preload="metadata">
              <source src="static/audios/elevenlabs_3.mp3" type="audio/mpeg" />
            </audio>
          </div>
          <div class="col">
            <div class="label">국내 TTS</div>
            <audio controls preload="metadata">
              <source src="static/audios/supertone_3.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">Ours</div>
            <audio controls preload="metadata">
              <source src="static/audios/ours3.wav" type="audio/wav" />
            </audio>
          </div>
        </div>
      </div>
    </section>

    <div class="divider"></div>
    <div class="footer-text">
      <p>
        안녕하세요. 채널톡 AI팀 스피치 조직의 <strong>Robin(신승윤)</strong>,
        <strong>Belle(김지우)</strong>, <strong>Day(안동하)</strong>,
        <strong>Luke(전승욱)</strong>입니다. 저희는
        AI 전화 상담을 위한 <strong>TTS (Text‑to‑Speech)</strong> 모델을 연구·개발하고 있습니다.
      </p>
    
      <p>여러 상용 TTS가 이미 존재하지만, 저희가 자체 모델을 만드는 이유는 명확합니다.</p>
      <ul>
        <li><strong>상담사향 프로소디</strong>의 일관성과 자연스러움이 부족합니다.</li>
        <li>
          한국어 특유의 <strong>상식 기반 발화</strong> 처리에 취약합니다
          (한·영 혼용, 날짜·시간, 주문/고유번호, URL·이메일 등).
        </li>
        <li>궁극적으로 <strong>정말 사람 같은 목소리</strong>를 만들어 자연스러운 상담 경험을 제공하고자 합니다.</li>
      </ul>
    
      <p>
        이를 개선하기 위해 공개/합성 데이터를 활용해 <strong>SFT(Supervised Fine-Tuning)</strong>을 수행하고,
        <strong>GRPO,DPO 등 RL 기반의 post-training</strong>을 추가 수행하여 실제 상담 시나리오에 적합한
        <strong>상담사향 발화(prosody)</strong>를 구현하는 방법을 제안합니다.
        이 페이지에서는 저희가 결과를 도출하기까지 직면했던 다양한 도전과제들과 이를 해결하기 위해 어떤 고민과 노력을 기울였는지를 소개하고자 합니다.
      </p>
    </div>

    <div class="divider"></div>
    <!-- Benchmark chart -->

    <h2>자체 벤치마크 성능 비교</h2>
    <figure class="chart">
      <img
        src="static/img/benchmark-normal.png"
        alt="Internal Testset (Normal) CER benchmark across models"
        loading="lazy"
      />
      <figcaption>
        <strong>그림 1.</strong> Channel TTS와 글로벌 TTS 경쟁모델들의 음성발화 벤치마크 성능 (CER) 비교 으로 낮을수록 성능이 좋습니다. 자체 모델(<em>Ours</em>)은 GRPO 이후 가장 낮은 CER을 달성했습니다. 대다수가 한글로만 구성된 internal testset으로 평가하였으며, 샘플레이트를 8khz (전화음성)로 변환하지 않고 각각 Provider 모델의 원본 샘플을 사용하였습니다.
      </figcaption>
    </figure>

    <h2>정성 평가</h2>
    <div class="footer-text">
      <p>
        위 벤치마크에는 측정하기 어려운 상담사향 발화 성능이 포함되어 있지 않습니다. <br> 예를 들어 상담의 복잡한 발화패턴, <strong>숫자류 (주문번호, 날짜, 시간, 전화번호 등) </strong> 과 같은 류의 발화는 STT (Speech-to-Text) 모델 성능의 한계로 인해 CER로 측정하기 어렵다는 단점이 있어 정성적으로 평가하였습니다.[2]
      </p>
    </div>

    <div class="divider"></div>

      <!-- Row 1 -->
      <div class="utterance-block">
        둥둥레스토랑 성인 요금은 평일 런치 19,992원, 평일 디너 25,940원, 주말 및 공휴일은 37,771원입니다.
        <div class="audios">
          <div class="col right">
            <div class="label">GPT-4o-mini-tts (sage)</div>
            <audio controls preload="metadata">
              <source src="static/audios/openai_4.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col wrong">
            <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
            <audio controls preload="metadata">
              <source src="static/audios/ElevenLabs_2025-08-20T14_27_13_Anna Kim_pvc_sp86_s50_sb50_se47_b_m2.mp3" type="audio/mpeg" />
            </audio>
          </div>
          <div class="col right">
            <div class="label">국내 TTS</div>
            <audio controls preload="metadata">
              <source src="static/audios/supertone_4.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col right">
            <div class="label">Ours</div>
            <audio controls preload="metadata">
              <source src="static/audios/audio-2025-08-20T232626.115.wav" type="audio/wav" />
            </audio>
          </div>
        </div>
      </div>
      <!-- Row 2 -->
      <div class="utterance-block">
        한국경제는 지난해보다 0.2%p 성장하는데 그쳤습니다.
        <div class="audios">
          <div class="col wrong">
            <div class="label">GPT-4o-mini-tts (sage)</div>
            <audio controls preload="metadata">
              <source src="static/audios/openai_5.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col wrong">
            <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
            <audio controls preload="metadata">
              <source src="static/audios/ElevenLabs_2025-08-20T14_32_12_Anna Kim_pvc_sp86_s50_sb50_se47_b_m2.mp3" type="audio/mpeg" />
            </audio>
          </div>
          <div class="col right">
            <div class="label">국내 TTS</div>
            <audio controls preload="metadata">
              <source src="static/audios/supertone_5.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col right">
            <div class="label">Ours</div>
            <audio controls preload="metadata">
              <source src="static/audios/audio - 2025-08-20T233341.844.wav" type="audio/wav" />
            </audio>
          </div>
        </div>
      </div>

      <!-- Row 3 -->
      <div class="utterance-block">
        안녕하세요. 저는 채널톡 AI 상담사 로빈입니다. 혹시 전화주신 분의 전화번호가 011-1234-1234 맞으실까요?
        <div class="audios">
          <div class="col right">
            <div class="label">GPT-4o-mini-tts (sage)</div>
            <audio controls preload="metadata">
              <source src="static/audios/openai_6.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col wrong">
            <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
            <audio controls preload="metadata">
              <source src="static/audios/ElevenLabs_2025-08-20T14_44_14_Anna Kim_pvc_sp86_s50_sb50_se47_b_m2.mp3" type="audio/mpeg" />
            </audio>
          </div>
          <div class="col wrong">
            <div class="label">국내 TTS</div>
            <audio controls preload="metadata">
              <source src="static/audios/supertone_6.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col right">
            <div class="label">Ours</div>
            <audio controls preload="metadata">
              <source src="static/audios/audio - 2025-08-20T234618.807.wav" type="audio/wav" />
            </audio>
          </div>
        </div>
      </div>
      <div class="divider"></div>

      <!-- Row 4 -->
      <div class="utterance-block">
        2025년 8월20일 ~ 2025년 8월 25일 까지 이벤트가 진행됩니다.
        <div class="audios">
          <div class="col wrong">
            <div class="label">GPT-4o-mini-tts (sage)</div>
            <audio controls preload="metadata">
              <source src="static/audios/openai_7.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col wrong">
            <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
            <audio controls preload="metadata">
              <source src="static/audios/ElevenLabs_2025-08-20T14_52_39_Anna Kim_pvc_sp86_s50_sb50_se47_b_m2.mp3" type="audio/mpeg" />
            </audio>
          </div>
          <div class="col wrong">
            <div class="label">국내 TTS</div>
            <audio controls preload="metadata">
              <source src="static/audios/supertone_7.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col right">
            <div class="label">Ours</div>
            <audio controls preload="metadata">
              <source src="static/audios/audio - 2025-08-20T234900.595.wav" type="audio/wav" />
            </audio>
          </div>
        </div>
      </div>
      <div class="divider"></div>

      <div class="footer-text">
        <p>
          흔히 정규표현식으로 이런 패턴을 처리할 수 있다고 생각할 수 있습니다. 
          하지만 전화번호만 해도 114, XXX-XXXX, XXX-XXXX-XXXX 등 형태가 다양하고 주문번호와 겹치는 경우도 많습니다. 
          따라서 모델이 자연스럽게 읽도록 학습하는 것이 더 바람직합니다. 
          가격의 경우 X,XXX원처럼 비교적 일정한 패턴이 많아 정규표현식으로 일부 대체할 수 있습니다. 
          또한 '%p'를 '퍼센트포인트'로 발화하는 것은 상식 기반 추론이 필요한 문제인데, 슈퍼톤과 저희 모델만 이를 올바르게 처리했습니다.
        </p>
        <p>
          뿐만 아니라, <strong>한영혼합문</strong> 발화에서도 취약한 모습을 보입니다.
        </p>
      </div>

    <div class="divider"></div>

    <!-- Row 1 -->
    <div class="utterance-block">
      ChatGPT 는 RAG를 통해 외부 실시간 지식에 접근할 수 있습니다.
      <div class="audios">
        <div class="col wrong">
          <div class="label">GPT-4o-mini-tts (sage)</div>
          <audio controls preload="metadata">
            <source src="static/audios/openai_8.wav" type="audio/wav" />
          </audio>
        </div>
        <div class="col wrong">
          <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
          <audio controls preload="metadata">
            <source src="static/audios/ElevenLabs_2025-08-20T15_10_07_Anna Kim_pvc_sp86_s50_sb50_se47_b_m2.mp3" type="audio/mpeg" />
          </audio>
        </div>
        <div class="col wrong">
          <div class="label">국내 TTS</div>
          <audio controls preload="metadata">
            <source src="static/audios/supertone_8.wav" type="audio/wav" />
          </audio>
        </div>
        <div class="col right">
          <div class="label">Ours</div>
          <audio controls preload="metadata">
            <source src="static/audios/audio - 2025-08-21T001414.443.wav" type="audio/wav" />
          </audio>
        </div>
      </div>
    </div>
    <div class="divider"></div>

    <!-- Row 2 -->
    <!--
    <div class="utterance-block">
      주문번호는 HXE23872 입니다.
      <div class="audios">
        <div class="col right">
          <div class="label">GPT-4o-mini-tts (sage)</div>
          <audio controls preload="metadata">
            <source src="static/audios/openai_9.wav" type="audio/wav" />
          </audio>
        </div>
        <div class="col wrong">
          <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
          <audio controls preload="metadata">
            <source src="static/audios/ElevenLabs_2025-08-20T15_17_06_Anna Kim_pvc_sp86_s50_sb50_se47_b_m2.mp3" type="audio/mpeg" />
          </audio>
        </div>
        <div class="col wrong">
          <div class="label">국내 TTS</div>
          <audio controls preload="metadata">
            <source src="static/audios/supertone_9.wav" type="audio/wav" />
          </audio>
        </div>
        <div class="col right">
          <div class="label">Ours</div>
          <audio controls preload="metadata">
            <source src="static/audios/audio - 2025-08-21T001807.186.wav" type="audio/wav" />
          </audio>
        </div>
      </div>
    </div>
    <div class="divider"></div>
    -->
    
    <!-- Row 3 -->
    <!--
    <div class="utterance-block">
      고객님 주문하신 상품은 어제 DHL Express로 출고되었고, 현재 tracking number는 ABC123456입니다. 배송 조회는 DHL 홈페이지에서 바로 확인 가능합니다.
      <div class="audios">
        <div class="col right">
          <div class="label">GPT-4o-mini-tts (sage)</div>
          <audio controls preload="metadata">
            <source src="static/audios/openai_10.wav" type="audio/wav" />
          </audio>
        </div>
        <div class="col wrong">
          <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
          <audio controls preload="metadata">
            <source src="static/audios/ElevenLabs_2025-08-20T15_21_32_Anna Kim_pvc_sp86_s50_sb50_se47_b_m2.mp3" type="audio/mpeg" />
          </audio>
        </div>
        <div class="col wrong">
          <div class="label">국내 TTS</div>
          <audio controls preload="metadata">
            <source src="static/audios/supertone_10.wav" type="audio/wav" />
          </audio>
        </div>
        <div class="col right">
          <div class="label">Ours</div>
          <audio controls preload="metadata">
            <source src="static/audios/audio - 2025-08-21T002440.213.wav" type="audio/wav" />
          </audio>
        </div>
      </div>
    </div>
    <div class="divider"></div>
    -->

    <div class="footer-text">
      <p>
        저희 모델 개발 과정에서 이슈가 있었습니다. 저희는 기본적으로 LLM으로 speech token을 생성하는 Llasa[1] 구조를 차용했기 때문에, LLM 에서 사용하는 방식으로 바로 GRPO[3] 를 통해 발화가 어색하거나 잘못된 fallback을 줄이기 위한 학습을 수행해 보았습니다. CER은 벤치마크에서 처럼 낮아졌지만 Side-Effect 로 발화가 monotone(마치 국어책 읽는듯한) 해지는 것이 문제였습니다.
      </p>
    </div>

    <!-- Row 1 -->
    <div class="divider"></div>
    <div class="utterance-block">
      안녕하세요. 저는 알프입니다. 무엇을 도와드릴까요?
      <div class="audios">
        <div class="col">
          <div class="label">Ours</div>
          <audio controls preload="metadata">
            <source src="static/audios/alf_intro.wav" type="audio/wav" />
          </audio>
        </div>
        <div class="col">
          <div class="label">Ours + GRPO</div>
          <audio controls preload="metadata">
            <source src="static/audios/grpo_alf_intro.wav" type="audio/wav" />
          </audio>
        </div>
      </div>
    </div>
    <div class="divider"></div>

    <section id="grpo" class="grpo-section">
      <h2>강화학습으로 더 잘하는 모델 만들기</h2>
    
      <div class="eq-card">
        <p class="eq-title">Objective</p>
        <p class="eq">
          \[
          \text{Reward}
          = \frac{\lambda_c + \lambda_n}
                 {\frac{\lambda_c}{U_{\mathrm{CER}}} + \frac{\lambda_n}{U_{\mathrm{NLL}}}}
          \]
        </p>
    
        <p class="eq-sub">유틸리티 정의</p>
        <p class="eq">
          \[
          U_{\mathrm{CER}} = 1 - \tanh(\beta_c \cdot \mathrm{CER}), \qquad
          U_{\mathrm{NLL}} = e^{-\frac{\mathrm{NLL}}{\tau_n}}
          \]
        </p>
      </div>
    
      <div class="footer-text">
        <ul>
          <li><strong>CER</strong>: 정답 텍스트와 Whisper 전사 간 <em>문자 오류율</em> (낮을수록 좋음)</li>
          <li><strong>NLL</strong>: Whisper 음향모델의 <em>Negative Log Likelihood</em> (낮을수록 좋음)</li>
          <li><strong>\(\beta_c\), \(\tau_n\)</strong>: 각 항의 민감도를 조절하는 하이퍼파라미터</li>
          <li><strong>\(\lambda_c\), \(\lambda_n\)</strong>: CER/NLL 중요도 가중치</li>
        </ul>
        <p>
          보상은 <strong>0–1</strong> 범위에서 값이 커질수록 더 좋은 발화로 간주됩니다.
          직관적으로는 <em>문자 오류(CER)를 줄이고</em>, <em>Whisper 관점의 발화 자연스러움(NLL)을 높이는</em> 방향으로 학습이 진행됩니다.
        </p>
        <p>
          본 수식의 문제점은 CER은 낮출 수 있지만 Prosody 에 대한 objective 가 없어 monotone 해지는 문제가 있다는 것입니다.
        </p>
        </div>
        <!-- 이미지 추가 -->
        <figure class="chart">
          <img src="static/img/grpo_f0_energy.png" alt="GRPO" class="grpo-image", style="width: 90%; height: auto; margin-top: 16px;">
          <figcaption>
            <strong>그림 2.</strong> GRPO 전 후 생성된 발화의 에너지 레벨 비교. 
          </figcaption>
        </figure>
        <div class="footer-text">
        <p>
          위 그림 2를 살펴보면 GRPO 를 하기전 모델 (baseline) 과  GRPO 를 하고 난 이후 모델의 internal testset 에서 생성된 오디오의 logF0 을 살펴보면  GRPO는 문장 내에서 저피치로 내려가는 구간이 덜하고, 평균 이상으로 유지되는 프레임이 더 많은걸 볼 수 있습니다. 이는 동일한 주파수대가 활용되며 상대적으로 <strong>모노톤한 억양</strong>이 나온다는 것을 확인할 수 있었습니다.
        </p>
      </div>
    </section>

    <div class="footer-text">
      <p>
        이러한 한계로 인해 <strong>GRPO objective에는 상담사형 억양(prosody)을 반영한 보상</strong>이 필요합니다. 
        그러나 prosody 자체를 정량적으로 정의하기는 모호하며, 
        매번 Online Rollout마다 사람이 직접 평가하는 방식은 
        <em>비효율적이고 비용 부담이 크다</em>는 문제가 있습니다.
      </p>
      <p>
        이에 저희는 먼저 RLHF의 가장 기본적이고 안정적인 접근법인 
        <strong>DPO (Direct Preference Optimization)</strong>를 적용하여 학습을 진행하였습니다.
      </p>
    </div>
    
    <div class="divider"></div>
    <div class="utterance-block">
      기존에 사용하던 유심은 재사용이 어렵기 때문에 통신사 변경시 새로운 유심을 구매해야합니다.
      <div class="audios">
        <div class="col wrong">
          <div class="label">Lose Sample</div>
          <audio controls preload="metadata">
            <source src="static/audios/dpo_loss_sample.wav" type="audio/wav" />
          </audio>
        </div>
        <div class="col right">
          <div class="label">Win Sample</div>
          <audio controls preload="metadata">
            <source src="static/audios/dpo_win_sample.wav" type="audio/wav" />
          </audio>
        </div>
      </div>
    </div>
    <div class="divider"></div>

    <div class="footer-text">
      <p>
      예를 들어 <code>기존에 사용하던 유심은 재사용이 어렵기 때문에 통신사 변경시 새로운 유심을 구매해야합니다.</code> 라는 문장이 있을 때,
      아래와 같이 두가지 샘플을 <span style="color: red;">Lose Sample</span> 과 <span style="color: blue;">Win Sample</span> 으로 사람이 듣고 직접 라벨링 할 수 있습니다.
      </p>

      <p>
      이런 샘플들을 여러개 모아 훈련하게 되면 모델은 더 좋은 발화를 생성하게 됩니다.
      </p>
    </div>

    <div class="divider"></div>
    <div class="utterance-block">
      안녕하세요 저는 알프입니다. 무엇을 도와드릴까요?
      <div class="audios">
        <div class="col">
          <div class="label">baseline</div>
          <audio controls preload="metadata">
            <source src="static/audios/alf_intro.wav" type="audio/wav" />
          </audio>
        </div>
        <div class="col">
          <div class="label">DPO</div>
          <audio controls preload="metadata">
            <source src="static/audios/dpo_alf_intro.wav" type="audio/wav" />
          </audio>
        </div>
        <div class="col">
          <div class="label">GRPO</div>
          <audio controls preload="metadata">
            <source src="static/audios/grpo_alf_intro.wav" type="audio/wav" />
          </audio>
        </div>
      </div>
    </div>
    <div class="divider"></div>
    
    <figure class="chart">
      <img 
        src="static/img/online-dpo.png" 
        alt="Online DPO 과정"
        loading="lazy"
        style="width: 90%; height: auto; margin-top: 16px;"
      />
      <figcaption>
        <strong>그림 3.</strong> Online DPO 학습 과정. 여러 라운드의 선호도 학습을 반복함으로써 발화 자연스러움과 문자 오류율(CER) 모두 개선됨.
      </figcaption>
    </figure>

    <div class="footer-text">
      <p>
      물론 baseline 과 GRPO는 CER은 매우 낮습니다. 그렇지만 상담사향이 아니기 때문에 실제 Real-World 상담에서 쓰기에는 무리가 있습니다.
      DPO를 처음하면 CER이 2배가까이 상승하지만 이를 반복함으로서 <strong>발화 오류를 교정하고 Prosody 또한 개선할 수 있음</strong>을 정량,정성적으로 확인할 수 있었습니다.
      </p>
    </div>

      <div class="divider"></div>
  <section id="future-work">
    <h2>Future Work</h2>
    <div class="footer-text">
      <p>
        본 연구에서는 GRPO와 DPO 기반의 학습을 통해 상담사향 발화를 개선할 수 있음을 확인했습니다. 
        그러나 여전히 <strong>prosody를 정량적으로 반영할 수 있는 보상 함수 설계</strong>는 남아 있는 과제입니다.
      </p>
      <p>
        향후 연구에서는 <strong>발화 유사도 기반 지표(Speaker embedding similarity)</strong>를 활용해 prosody를 더 직접적으로 반영하거나, 
        <strong>휴먼 평가 데이터</strong>를 RL 보상에 결합하는 방향을 모색할 예정입니다. 
        또한 전화 상담 환경에서의 <strong>잡음·중단·혼합언어</strong> 발화에 대한 강건성을 확보하는 것도 중요한 목표입니다.
      </p>
      <p>
        추가적으로 <strong>data curation</strong>을 정교하게 수행하여 [4]와 같은 
        고품질 데이터 기반 훈련 방식을 적용하는 것도 중요한 향후 연구 방향입니다.
      </p>
    </div>
  </section>


    <!-- 참고문헌 -->
    <section id="references">
      <h2>참고문헌</h2>
      <div class="footer-text">
        <p>[1] Ye, Zhen, et al. "Llasa: Scaling train-time and inference-time compute for llama-based speech synthesis." arXiv preprint arXiv:2502.04128 (2025).</p>
        <p>[2] Karita, Shigeki, Richard Sproat, and Haruko Ishikawa. "Lenient evaluation of Japanese speech recognition: Modeling naturally occurring spelling inconsistency." arXiv preprint arXiv:2306.04530 (2023).</p>
        <p>[3] Shao, Zhihong, et al. "Deepseekmath: Pushing the limits of mathematical reasoning in open language models." arXiv preprint arXiv:2402.03300 (2024).</p>
        <p>[4] Darefsky, Jordan, Ge Zhu, and Zhiyao Duan. "Parakeet." 2024. Available at: <a href="https://jordandarefsky.com/blog/2024/parakeet/" target="_blank">https://jordandarefsky.com/blog/2024/parakeet/</a></p>
      </div>
    </section>


    <div class="divider"></div>
    <footer>© 2025 channel.io — Channel TTS: Towards Real-World Prosody for Conversational Agents</footer>
  </div>

  <script>
    // 하나 재생 시 나머지는 정지 (겹침 방지)
    const players = Array.from(document.querySelectorAll('audio'));
    players.forEach(a => a.addEventListener('play', () =>
      players.forEach(b => { if (b !== a) b.pause(); })
    ));

      // Live Demo TTS 스트리밍 기능
      (function() {
        // CORS 설정 완료 - 프록시 필요 없음!
        const HOST = "https://ch-tts-streaming-demo.exp.channel.io";
        const playBtn = document.getElementById('demo-play-btn');
        const stopBtn = document.getElementById('demo-stop-btn');
        const clearBtn = document.getElementById('demo-clear-btn');
        const textArea = document.getElementById('demo-text');
        const statusDiv = document.getElementById('demo-status');
      
      let audioContext = null;
      let currentSource = null;
      let isPlaying = false;

      function setStatus(message, type = 'info') {
        statusDiv.textContent = message;
        statusDiv.className = 'demo-status demo-status-' + type;
      }

      function updateButtons(playing) {
        isPlaying = playing;
        playBtn.disabled = playing;
        stopBtn.disabled = !playing;
      }

      async function playTTS() {
        const text = textArea.value.trim();
        if (!text) {
          setStatus('⚠️ 텍스트를 입력해주세요.', 'warning');
          return;
        }

        try {
          updateButtons(true);
          setStatus('🔄 음성 생성 중...', 'loading');

          // AudioContext 초기화
          if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
          }

          // API 호출
          const response = await fetch(`${HOST}/v1/text-to-speech/test-voice/stream?optimize_streaming_latency=0`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Accept': 'audio/pcm,*/*'
            },
            body: JSON.stringify({
              text: text,
              output_format: 'pcm_24000'
            })
          });

          if (!response.ok) {
            throw new Error(`API 오류: ${response.status} ${response.statusText}`);
          }

          setStatus('▶️ 재생 중...', 'playing');

          // 스트리밍 데이터를 받아서 재생
          const reader = response.body.getReader();
          const chunks = [];
          
          while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            chunks.push(value);
          }

          // 모든 chunk를 하나의 배열로 합치기
          const totalLength = chunks.reduce((acc, chunk) => acc + chunk.length, 0);
          const pcmData = new Uint8Array(totalLength);
          let offset = 0;
          for (const chunk of chunks) {
            pcmData.set(chunk, offset);
            offset += chunk.length;
          }

          // PCM을 AudioBuffer로 변환 (16-bit signed little-endian, mono, 24000Hz)
          const int16Array = new Int16Array(pcmData.buffer);
          const float32Array = new Float32Array(int16Array.length);
          
          // int16 -> float32 변환 (-1.0 ~ 1.0)
          for (let i = 0; i < int16Array.length; i++) {
            float32Array[i] = int16Array[i] / 32768.0;
          }

          // AudioBuffer 생성
          const audioBuffer = audioContext.createBuffer(1, float32Array.length, 24000);
          audioBuffer.getChannelData(0).set(float32Array);

          // 재생
          currentSource = audioContext.createBufferSource();
          currentSource.buffer = audioBuffer;
          currentSource.connect(audioContext.destination);
          
          currentSource.onended = () => {
            updateButtons(false);
            setStatus('✅ 재생 완료', 'success');
            currentSource = null;
          };

          currentSource.start(0);

        } catch (error) {
          console.error('TTS Error:', error);
          setStatus(`❌ 오류: ${error.message}`, 'error');
          updateButtons(false);
        }
      }

      function stopTTS() {
        if (currentSource) {
          currentSource.stop();
          currentSource = null;
        }
        updateButtons(false);
        setStatus('⏹️ 정지됨', 'info');
      }

      playBtn.addEventListener('click', playTTS);
      stopBtn.addEventListener('click', stopTTS);
      clearBtn.addEventListener('click', () => {
        textArea.value = '';
        textArea.focus();
        setStatus('', 'info');
      });
    })();
  </script>
</body>
</html>
