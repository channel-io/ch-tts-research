<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Channel TTS Demo — Audio Comparisons</title>
  <meta name="color-scheme" content="light dark">
  <link rel="stylesheet" href="static/css/style.css">
</head>
<body>
  <div class="container">
    <!-- Header -->
    <header class="nav">
      <div class="brand">
        <picture class="brand-logo">
          <!-- 다크 모드에서는 흰 로고 사용 -->
          <source srcset="static/img/ch-logo-white-ko.png" media="(prefers-color-scheme: dark)">
          <!-- 라이트 모드에서는 보라+검정 로고 -->
          <img src="static/img/ch-logo-ko.png" alt="채널톡 로고" class="brand-logo-img" />
        </picture>
      </div>
      <div class="nav-actions">
        <a class="btn" href="https://channel.io" target="_blank" rel="noopener">더 알아보기 →</a>
      </div>
    </header>
    

    <!-- Hero (논문 타이틀 스타일) -->
    <section class="hero">
      <h1 class="title">Channel TTS: Towards Real-World Prosody for Conversational Agents</h1>
    
      <p class="authors">
        <a href="https://seungyounshin.github.io" target="_blank">Seungyoun Shin</a><sup>1</sup>, 
        <a href="https://skswldndi.github.io" target="_blank">Jiwoo Kim</a><sup>1</sup>, 
        Dongha Ahn<sup>1</sup>, 
        Sungwook Jeon<sup>1</sup>
      </p>
      <p class="affiliation"><sup>1</sup>Channel Corp.</p>
    
      <div class="links">
        <a class="link-btn" href="#">🎧 Demo</a>
        <a class="link-btn" href="#">📄 Paper</a>
        <a class="link-btn" href="#">💻 Code</a>
      </div>
    </section>


    <!-- 듣기 비교 -->
    <section id="listen" class="listen">
      <h2>오디오 비교</h2>
      <p class="note"></p>*전화는 8Khz이기 때문에 모두 <strong>8Khz로 변환</strong>하였습니다.</p>

      <div class="divider"></div>
      <!-- Row 1 -->
      <div class="utterance-block">
        안녕하세요 채널톡 AI 에이전트 알프입니다.
        <div class="audios">
          <div class="col">
            <div class="label">GPT-4o-mini-tts (sage)</div>
            <audio controls preload="metadata">
              <source src="static/audios/openai_1_8khz.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
            <audio controls preload="metadata">
              <source src="static/audios/elevenlabs_1_8khz.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">Supertone</div>
            <audio controls preload="metadata">
              <source src="static/audios/supertone_1_8khz.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">Ours</div>
            <audio controls preload="metadata">
              <source src="static/audios/ours_1_8khz.wav" type="audio/wav" />
            </audio>
          </div>
        </div>
      </div>
      <div class="divider"></div>

      <!-- Row 2 -->
      <div class="utterance-block">
        서류상 이상이 있다면 알려주시면 감사하겠습니다.
        <div class="audios">
          <div class="col">
            <div class="label">GPT-4o-mini-tts (sage)</div>
            <audio controls preload="metadata">
              <source src="static/audios/openai_2_8khz.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
            <audio controls preload="metadata">
              <source src="static/audios/elevenlabs_2_8khz.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">Supertone</div>
            <audio controls preload="metadata">
              <source src="static/audios/supertone_2_8khz.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">Ours</div>
            <audio controls preload="metadata">
              <source src="static/audios/ours2_8khz.wav" type="audio/wav" />
            </audio>
          </div>
        </div>
      </div>
      <div class="divider"></div>

      <!-- Row 3 -->
      <div class="utterance-block">
        FAQ나 도큐먼트에서 '홈페이지 주소를 입력하거나 이미지를 등록하면 텍스트, 이미지 등을 크롤링하여 답변하는 기능'에 대한 정보가 없어 조금 더 자세한 설명을 부탁드려도 될까요?
        <div class="audios">
          <div class="col">
            <div class="label">GPT-4o-mini-tts (sage)</div>
            <audio controls preload="metadata">
              <source src="static/audios/openai_3_8khz.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">ElevenLabs (Multilingual v2 - Anna Kim)</div>
            <audio controls preload="metadata">
              <source src="static/audios/elevenlabs_3_8khz.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">Supertone</div>
            <audio controls preload="metadata">
              <source src="static/audios/supertone_3_8khz.wav" type="audio/wav" />
            </audio>
          </div>
          <div class="col">
            <div class="label">Ours</div>
            <audio controls preload="metadata">
              <source src="static/audios/ours3_8khz.wav" type="audio/wav" />
            </audio>
          </div>
        </div>
      </div>
    </section>

    <div class="divider"></div>
    <div class="footer-text">
      <p>
        안녕하세요. 채널톡 AI팀 스피치 조직의 <strong>Robin(신승윤)</strong>,
        <strong>Belle(김지우)</strong>, <strong>Day(안동하)</strong>,
        <strong>Luke(전승욱)</strong>입니다. 저희는
        AI 전화 상담을 위한 <strong>TTS (Text‑to‑Speech)</strong> 모델을 연구·개발하고 있습니다.
      </p>
    
      <p>여러 상용 TTS가 이미 존재하지만, 저희가 자체 모델을 만드는 이유는 명확합니다.</p>
      <ul>
        <li><strong>상담사형 프로소디</strong>의 일관성과 자연스러움이 부족합니다.</li>
        <li>
          한국어 특유의 <strong>상식 기반 발화</strong> 처리에 취약합니다
          (한·영 혼용, 날짜·시간, 주문/고유번호, URL·이메일 등).
        </li>
        <li>궁극적으로 <strong>정말 사람 같은 목소리</strong>를 만들어 자연스러운 상담 경험을 제공하고자 합니다.</li>
      </ul>
    
      <p>
        이를 개선하기 위해 공개/합성 데이터를 활용해 <strong>SFT(Supervised Fine-Tuning)</strong>을 수행하고,
        <strong>GRPO,DPO 등 RL</strong>을 추가 수행하여 실제 상담 시나리오에 적합한
        <strong>상담사형 발화(prosody)</strong>를 구현하는 방법을 제안합니다.
        이 페이지에서는 저희가 결과를 도출하기까지 직면했던 다양한 도전과제들과, 이를 해결하기 위해 어떤 고민과 노력을 기울였는지를 상세히 소개하고자 합니다.
      </p>
    </div>

    <!-- Benchmark chart -->
    <figure class="chart">
      <img
        src="static/img/benchmark-normal.png"
        alt="Internal Testset (Normal) CER benchmark across models"
        loading="lazy"
      />
      <figcaption>
        <strong>그림 1.</strong> Channel TTS와 글로벌 TTS 경쟁모델들의 음성발화 벤치마크 성능 비교. 낮을수록 성능이 좋습니다. 우리 모델(<em>Ours</em>)은 GRPO 이후 가장 낮은 CER을 달성했습니다.
      </figcaption>
    </figure>

    
    <div class="divider"></div>

    <!-- 채널톡 TTS 모델 -->
    <section id="model">
      <h2>채널톡 TTS 모델</h2>
      <div class="footer-text"> 
      <p>곧 내용이 업데이트될 예정입니다.</p>
      </div>
    </section>

    <div class="divider"></div>

    <!-- 데이터셋 큐레이션 -->
    <section id="dataset">
      <h2>데이터셋 큐레이션</h2>
      <div class="footer-text">
        <p>Dataset 관련 세부 내용이 여기에 추가될 예정입니다.</p>
      </div>
    </section>

    <div class="divider"></div>

    <!-- 훈련 및 실험 -->
    <section id="training">
      <h2>훈련 및 실험</h2>
      <div class="footer-text">
      <ul>
        <li>기본적인 훈련 단계 (예: 36,000시간)</li>
        <li>GRPO</li>
        <li>DPO</li>
      </ul>
      <p>훈련 및 실험 결과가 여기에 추가될 예정입니다.</p>
      </div>
    </section>

    <div class="divider"></div>

    <!-- 참고문헌 -->
    <section id="references">
      <h2>참고문헌</h2>
      <div class="footer-text">
        <p>[1] Ye, Zhen, et al. "Llasa: Scaling train-time and inference-time compute for llama-based speech synthesis." arXiv preprint arXiv:2502.04128 (2025).</p>
      </div>
    </section>


    <div class="divider"></div>
    <footer>© 2025 channel.io — Channel TTS: Towards Real-World Prosody for Conversational Agents</footer>
  </div>

  <script>
    // 하나 재생 시 나머지는 정지 (겹침 방지)
    const players = Array.from(document.querySelectorAll('audio'));
    players.forEach(a => a.addEventListener('play', () =>
      players.forEach(b => { if (b !== a) b.pause(); })
    ));
  </script>
</body>
</html>
